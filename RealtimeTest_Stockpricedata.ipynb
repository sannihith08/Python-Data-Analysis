{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tvxBI7j5uklQ"
      },
      "outputs": [],
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import os\n",
        "import numpy as np\n",
        "#import ta\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "#import talib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "def save_nse_stocks_data(tickers, output_folder=\"nse_stock_data\"):\n",
        "    \"\"\"\n",
        "    Fetch and save 15-minute stock data for Indian stocks on NSE.\n",
        "    Each stock's data is saved to a separate CSV file.\n",
        "\n",
        "    :param tickers: List of stock tickers (e.g., RELIANCE.NS, TCS.NS).\n",
        "    :param output_folder: Directory to save the CSV files.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    # Ensure the output folder exists\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    for ticker in tickers:\n",
        "        try:\n",
        "            print(f\"Fetching data for {ticker}...\")\n",
        "\n",
        "            # Fetch 15-minute interval data for the last trading day\n",
        "            data = yf.download(tickers=ticker, period=\"1d\", interval=\"1m\")\n",
        "\n",
        "            # Check if the index is already timezone-aware\n",
        "           # print(f\"Timezone information: {data.index.tz}\")\n",
        "\n",
        "            # If the index is timezone-naive (no timezone information), localize to UTC\n",
        "            if data.index.tz is None:\n",
        "                data.index = data.index.tz_localize(\"UTC\")\n",
        "            else:\n",
        "                # If the index already has timezone information, directly convert it to IST\n",
        "                data.index = data.index.tz_convert(\"Asia/Kolkata\")\n",
        "\n",
        "            # Display the adjusted datetime (in IST)\n",
        "            print(data.index)\n",
        "\n",
        "\n",
        "            data.reset_index(inplace=True)\n",
        "\n",
        "           # data.index = data.index.tz_localize(\"UTC\").tz_convert(\"Asia/Kolkata\")\n",
        "            # Add a column for when the data was fetched\n",
        "            data['Fetched_At'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "\n",
        "            # Calculate cumulative price-volume and cumulative volume\n",
        "\n",
        "\n",
        "            # Define output file path\n",
        "            output_file = os.path.join(output_folder, f\"{ticker.replace('.NS', '')}_1min.csv\")\n",
        "\n",
        "            # Save to CSV (append if file exists)\n",
        "            if not os.path.exists(output_file):\n",
        "                data.to_csv(output_file, index=False)\n",
        "            else:\n",
        "                data.to_csv(output_file, mode='a', header=False, index=False)\n",
        "\n",
        "            print(f\"Data for {ticker} saved to {output_file}.\")\n",
        "\n",
        "            # from google.colab import files\n",
        "            # ticker = \"TITAN.NS\"\n",
        "            # localfile=\"C:\\\\Users\\\\srudroju\\\\OneDrive - hsconline\\\\Sannihith-Reports\\\\a\"\n",
        "            # local_file = f\"{ticker}_15min_data.csv\"\n",
        "            # data.to_csv(local_file)\n",
        "            # files.download(local_file)\n",
        "\n",
        "            # uploaded = files.upload()\n",
        "\n",
        "            # # Get the uploaded file name\n",
        "            # filename = list(uploaded.keys())[0]\n",
        "            # uploaded_data = pd.read_csv(filename)\n",
        "\n",
        "            # Display the first few rows of the uploaded data\n",
        "            #print(uploaded_data.head())\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching data for {ticker}: {e}\")\n",
        "\n",
        "# List of NSE stock tickers\n",
        "nse_tickers = [\"ZENTEC.NS\", \"TITAN.NS\",\"CHOLAFIN.NS\",\"TCS.NS\"]\n",
        "#nse_tickers = [\"TORNTPOWER.NS\"]\n",
        "\n",
        "# Save the data\n",
        "save_nse_stocks_data(nse_tickers)\n",
        "\n",
        "\n",
        "\n",
        "# Download file\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nh_B5DWuuqb9",
        "outputId": "fbe44aaa-f1b4-4f06-d835-0529c6172fb6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching data for ZENTEC.NS...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatetimeIndex(['2025-01-06 09:15:00+05:30', '2025-01-06 09:16:00+05:30',\n",
            "               '2025-01-06 09:17:00+05:30', '2025-01-06 09:18:00+05:30',\n",
            "               '2025-01-06 09:19:00+05:30', '2025-01-06 09:20:00+05:30',\n",
            "               '2025-01-06 09:21:00+05:30', '2025-01-06 09:22:00+05:30',\n",
            "               '2025-01-06 09:23:00+05:30', '2025-01-06 09:24:00+05:30',\n",
            "               ...\n",
            "               '2025-01-06 15:20:00+05:30', '2025-01-06 15:21:00+05:30',\n",
            "               '2025-01-06 15:22:00+05:30', '2025-01-06 15:23:00+05:30',\n",
            "               '2025-01-06 15:24:00+05:30', '2025-01-06 15:25:00+05:30',\n",
            "               '2025-01-06 15:26:00+05:30', '2025-01-06 15:27:00+05:30',\n",
            "               '2025-01-06 15:28:00+05:30', '2025-01-06 15:29:00+05:30'],\n",
            "              dtype='datetime64[ns, Asia/Kolkata]', name='Datetime', length=374, freq=None)\n",
            "Data for ZENTEC.NS saved to nse_stock_data/ZENTEC_1min.csv.\n",
            "Fetching data for TITAN.NS...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatetimeIndex(['2025-01-06 09:15:00+05:30', '2025-01-06 09:16:00+05:30',\n",
            "               '2025-01-06 09:17:00+05:30', '2025-01-06 09:18:00+05:30',\n",
            "               '2025-01-06 09:19:00+05:30', '2025-01-06 09:20:00+05:30',\n",
            "               '2025-01-06 09:21:00+05:30', '2025-01-06 09:22:00+05:30',\n",
            "               '2025-01-06 09:23:00+05:30', '2025-01-06 09:24:00+05:30',\n",
            "               ...\n",
            "               '2025-01-06 15:20:00+05:30', '2025-01-06 15:21:00+05:30',\n",
            "               '2025-01-06 15:22:00+05:30', '2025-01-06 15:23:00+05:30',\n",
            "               '2025-01-06 15:24:00+05:30', '2025-01-06 15:25:00+05:30',\n",
            "               '2025-01-06 15:26:00+05:30', '2025-01-06 15:27:00+05:30',\n",
            "               '2025-01-06 15:28:00+05:30', '2025-01-06 15:29:00+05:30'],\n",
            "              dtype='datetime64[ns, Asia/Kolkata]', name='Datetime', length=374, freq=None)\n",
            "Data for TITAN.NS saved to nse_stock_data/TITAN_1min.csv.\n",
            "Fetching data for CHOLAFIN.NS...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatetimeIndex(['2025-01-06 09:15:00+05:30', '2025-01-06 09:16:00+05:30',\n",
            "               '2025-01-06 09:17:00+05:30', '2025-01-06 09:18:00+05:30',\n",
            "               '2025-01-06 09:19:00+05:30', '2025-01-06 09:20:00+05:30',\n",
            "               '2025-01-06 09:21:00+05:30', '2025-01-06 09:22:00+05:30',\n",
            "               '2025-01-06 09:23:00+05:30', '2025-01-06 09:24:00+05:30',\n",
            "               ...\n",
            "               '2025-01-06 15:20:00+05:30', '2025-01-06 15:21:00+05:30',\n",
            "               '2025-01-06 15:22:00+05:30', '2025-01-06 15:23:00+05:30',\n",
            "               '2025-01-06 15:24:00+05:30', '2025-01-06 15:25:00+05:30',\n",
            "               '2025-01-06 15:26:00+05:30', '2025-01-06 15:27:00+05:30',\n",
            "               '2025-01-06 15:28:00+05:30', '2025-01-06 15:29:00+05:30'],\n",
            "              dtype='datetime64[ns, Asia/Kolkata]', name='Datetime', length=375, freq=None)\n",
            "Data for CHOLAFIN.NS saved to nse_stock_data/CHOLAFIN_1min.csv.\n",
            "Fetching data for TCS.NS...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatetimeIndex(['2025-01-06 09:15:00+05:30', '2025-01-06 09:16:00+05:30',\n",
            "               '2025-01-06 09:17:00+05:30', '2025-01-06 09:18:00+05:30',\n",
            "               '2025-01-06 09:19:00+05:30', '2025-01-06 09:20:00+05:30',\n",
            "               '2025-01-06 09:21:00+05:30', '2025-01-06 09:22:00+05:30',\n",
            "               '2025-01-06 09:23:00+05:30', '2025-01-06 09:24:00+05:30',\n",
            "               ...\n",
            "               '2025-01-06 15:20:00+05:30', '2025-01-06 15:21:00+05:30',\n",
            "               '2025-01-06 15:22:00+05:30', '2025-01-06 15:23:00+05:30',\n",
            "               '2025-01-06 15:24:00+05:30', '2025-01-06 15:25:00+05:30',\n",
            "               '2025-01-06 15:26:00+05:30', '2025-01-06 15:27:00+05:30',\n",
            "               '2025-01-06 15:28:00+05:30', '2025-01-06 15:29:00+05:30'],\n",
            "              dtype='datetime64[ns, Asia/Kolkata]', name='Datetime', length=375, freq=None)\n",
            "Data for TCS.NS saved to nse_stock_data/TCS_1min.csv.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXhVyEvdvfyG",
        "outputId": "0c6230cb-72f8-4251-f5ca-f618a84c2bdf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ta\n",
            "  Downloading ta-0.11.0.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ta) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from ta) (2.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->ta) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ta) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->ta) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->ta) (1.17.0)\n",
            "Building wheels for collected packages: ta\n",
            "  Building wheel for ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ta: filename=ta-0.11.0-py3-none-any.whl size=29412 sha256=4b9e2c2efecaa2ef815870ca24165e864057ac56a23c0ee64a52f99cf1f3ab8c\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/67/4f/8a9f252836e053e532c6587a3230bc72a4deb16b03a829610b\n",
            "Successfully built ta\n",
            "Installing collected packages: ta\n",
            "Successfully installed ta-0.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM technuque\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from ta.momentum import RSIIndicator\n",
        "from ta.trend import MACD\n",
        "from ta.volatility import BollingerBands\n",
        "\n",
        "# Step 1: Fetch One-Minute Interval Data\n",
        "#filepath='/content/nse_stock_data/TORNTPHARM_15min.csv'\n",
        "#filepath='/content/nse_stock_data/TITAN_1min.csv'\n",
        "filepath='/content/nse_stock_data/ZENTEC_1min.csv'\n",
        "# filepath= r'C:\\Users\\srudroju\\Downloads\\TITAN_NS_15min_data.csv'\n",
        "# print(filepath)\n",
        "data=pd.read_csv(filepath)\n",
        "\n",
        "data=data.drop(index=0)\n",
        "# Reset index to access the datetime column\n",
        "data.reset_index(inplace=True)\n",
        "\n",
        "data['Close']=pd.to_numeric(data['Close'], errors='coerce')\n",
        "\n",
        "# Step 2: Add Technical Indicators\n",
        "data['Delta'] = data['Close'].diff()  # Delta (difference between consecutive Close prices)\n",
        "data['RSI'] = RSIIndicator(close=data['Close'], window=14).rsi()\n",
        "\n",
        "# Calculate MACD and Signal Line\n",
        "macd = MACD(close=data['Close'], window_slow=26, window_fast=12, window_sign=9)\n",
        "data['MACD'] = macd.macd()\n",
        "data['MACD_signal'] = macd.macd_signal()\n",
        "\n",
        "\n",
        "# Add Bollinger Bands\n",
        "bollinger = BollingerBands(close=data['Close'], window=20)\n",
        "data['BB_upper'] = bollinger.bollinger_hband()\n",
        "data['BB_lower'] = bollinger.bollinger_lband()\n",
        "\n",
        "# Add Lag Features\n",
        "for lag in [1, 3, 5, 10]:\n",
        "    data[f'Close_lag_{lag}'] = data['Close'].shift(lag)\n",
        "data['Datetime'] = pd.to_datetime(data['Datetime'], errors='coerce')\n",
        "# Add Time-Based Features\n",
        "data['Hour'] = data['Datetime'].dt.hour\n",
        "data['Minute'] = data['Datetime'].dt.minute\n",
        "\n",
        "# Drop rows with NaN values\n",
        "data.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "wjpYY9Wsu3l9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale Data\n",
        "scaler = MinMaxScaler()\n",
        "scaled_data = scaler.fit_transform(data[['Open', 'High', 'Low', 'Close', 'Delta', 'RSI', 'MACD', 'MACD_signal',\n",
        "                                         'BB_upper', 'BB_lower', 'Hour', 'Minute']])\n",
        "\n",
        "# Prepare Sequences\n",
        "sequence_length = 15  # 15-minute sequence\n",
        "X, y = [], []\n",
        "for i in range(sequence_length, len(scaled_data)):\n",
        "    X.append(scaled_data[i-sequence_length:i])\n",
        "    y.append(scaled_data[i, 3])  # Close price is the target\n",
        "\n",
        "X, y = np.array(X), np.array(y)\n",
        "\n",
        "# Split Data into Train/Test Sets\n",
        "split = int(0.8 * len(X))\n",
        "X_train, X_test = X[:split], X[split:]\n",
        "y_train, y_test = y[:split], y[split:]\n"
      ],
      "metadata": {
        "id": "7vHf-u_nvBMh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Define the Model\n",
        "model = Sequential([\n",
        "    LSTM(64, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "    Dropout(0.2),\n",
        "    LSTM(64, return_sequences=False),\n",
        "    Dropout(0.2),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1)  # Predict Close Price\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()\n",
        "\n",
        "# Train the Model\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=32, callbacks=[early_stopping])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 863
        },
        "id": "pBi-VTBWvrXX",
        "outputId": "c835f43d-3571-4987-b350-88bbaa5e5bca"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │          \u001b[38;5;34m19,712\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m33,024\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m33\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">19,712</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m54,849\u001b[0m (214.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">54,849</span> (214.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m54,849\u001b[0m (214.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">54,849</span> (214.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - loss: 0.1311 - val_loss: 0.0223\n",
            "Epoch 2/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0140 - val_loss: 0.0076\n",
            "Epoch 3/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0088 - val_loss: 0.0084\n",
            "Epoch 4/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0072 - val_loss: 0.0063\n",
            "Epoch 5/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0057 - val_loss: 0.0066\n",
            "Epoch 6/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0054 - val_loss: 0.0056\n",
            "Epoch 7/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0060 - val_loss: 0.0061\n",
            "Epoch 8/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0052 - val_loss: 0.0051\n",
            "Epoch 9/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0059 - val_loss: 0.0057\n",
            "Epoch 10/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0047 - val_loss: 0.0055\n",
            "Epoch 11/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0041 - val_loss: 0.0052\n",
            "Epoch 12/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0042 - val_loss: 0.0060\n",
            "Epoch 13/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0046 - val_loss: 0.0054\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e0c87ae8ca0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make Predictions\n",
        "predictions = model.predict(X_test)\n",
        "predicted_close = scaler.inverse_transform(np.column_stack((\n",
        "    np.zeros((len(predictions), 3)), predictions, np.zeros((len(predictions), 8))\n",
        ")))[:, 3]\n",
        "\n",
        "# Add Predicted Close Prices to Dataset\n",
        "test_data = data.iloc[-len(y_test):].copy()\n",
        "test_data['Predicted_Close'] = predicted_close\n",
        "test_data['Actual_Close'] = scaler.inverse_transform(np.column_stack((\n",
        "    np.zeros((len(y_test), 3)), y_test.reshape(-1, 1), np.zeros((len(y_test), 8))\n",
        ")))[:, 3]\n",
        "\n",
        "# Save or Display Results\n",
        "test_data[['Datetime', 'Open', 'High', 'Low', 'Close', 'Actual_Close', 'Predicted_Close']].to_csv(\"enhanced_predictions.csv\", index=False)\n",
        "print(test_data[['Datetime', 'Open', 'High', 'Low', 'Close', 'Actual_Close', 'Predicted_Close']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dekke7ghvwFE",
        "outputId": "32a11548-3525-41d6-cfae-b13011960a78"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 343ms/step\n",
            "                     Datetime               Open               High  \\\n",
            "308 2025-01-06 14:23:00+05:30  2438.050048828125  2440.050048828125   \n",
            "309 2025-01-06 14:24:00+05:30  2439.449951171875             2439.5   \n",
            "310 2025-01-06 14:25:00+05:30   2437.85009765625   2441.10009765625   \n",
            "311 2025-01-06 14:26:00+05:30  2438.449951171875  2442.800048828125   \n",
            "312 2025-01-06 14:27:00+05:30  2439.199951171875  2442.050048828125   \n",
            "\n",
            "                   Low        Close  Actual_Close  Predicted_Close  \n",
            "308  2433.449951171875  2435.000000   2435.000000      2442.463577  \n",
            "309             2433.0  2437.899902   2437.899902      2442.298204  \n",
            "310   2437.85009765625  2441.100098   2441.100098      2442.314400  \n",
            "311  2438.449951171875  2442.800049   2442.800049      2442.503095  \n",
            "312   2437.10009765625  2437.100098   2437.100098      2442.992375  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "REat time data --Testing # New Section\n",
        "\n",
        "*   List item\n",
        "*   List item\n",
        "\n"
      ],
      "metadata": {
        "id": "CMHgpfGXwC2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tesing with real time data\n",
        "import yfinance as yf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from ta.momentum import RSIIndicator\n",
        "from ta.trend import MACD\n",
        "from ta.volatility import BollingerBands\n",
        "\n",
        "# Step 1: Fetch Real-Time Data (latest 15 minutes)\n",
        "data = yf.download(\"ZENTEC.NS\", interval=\"1m\", period=\"1d\")\n",
        "\n",
        "# Reset index to make sure we can access datetime easily\n",
        "data.reset_index(inplace=True)\n",
        "\n",
        "# Flatten the multi-level columns (Price and Ticker columns)\n",
        "data.columns = [col[0] if isinstance(col, tuple) else col for col in data.columns]\n",
        "\n",
        "# Drop the first row if necessary (it may contain extra metadata)\n",
        "data.drop(index=0, inplace=True)\n",
        "\n",
        "# Step 2: Preprocess the Data (Add Technical Indicators)\n",
        "data['Delta'] = data['Close'].diff()  # Delta (difference between consecutive Close prices)\n",
        "data['RSI'] = RSIIndicator(close=data['Close'], window=14).rsi()\n",
        "\n",
        "# Calculate MACD and Signal Line\n",
        "macd = MACD(close=data['Close'], window_slow=26, window_fast=12, window_sign=9)\n",
        "data['MACD'] = macd.macd()\n",
        "data['MACD_signal'] = macd.macd_signal()\n",
        "\n",
        "# Add Bollinger Bands\n",
        "bollinger = BollingerBands(close=data['Close'], window=20)\n",
        "data['BB_upper'] = bollinger.bollinger_hband()\n",
        "data['BB_lower'] = bollinger.bollinger_lband()\n",
        "\n",
        "# Add Lag Features\n",
        "for lag in [1, 3, 5, 10]:\n",
        "    data[f'Close_lag_{lag}'] = data['Close'].shift(lag)\n",
        "\n",
        "# Add Time-Based Features\n",
        "data['Hour'] = data['Datetime'].dt.hour\n",
        "data['Minute'] = data['Datetime'].dt.minute\n",
        "\n",
        "# Drop rows with NaN values\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "# Step 3: Scale the Data (to match the LSTM input)\n",
        "scaler = MinMaxScaler()\n",
        "scaled_data = scaler.fit_transform(data[['Open', 'High', 'Low', 'Close', 'Delta', 'RSI', 'MACD', 'MACD_signal',\n",
        "                                         'BB_upper', 'BB_lower', 'Hour', 'Minute']])\n",
        "\n",
        "# Prepare Sequences for LSTM (assuming the sequence length is 15)\n",
        "sequence_length = 15\n",
        "X_real_time = []\n",
        "for i in range(sequence_length, len(scaled_data)):\n",
        "    X_real_time.append(scaled_data[i-sequence_length:i])\n",
        "\n",
        "X_real_time = np.array(X_real_time)\n",
        "\n",
        "# Make Predictions (using the trained LSTM model)\n",
        "predictions = model.predict(X_real_time)\n",
        "\n",
        "# Inverse transform to get the original price scale\n",
        "predicted_close = scaler.inverse_transform(np.column_stack((\n",
        "    np.zeros((len(predictions), 3)), predictions, np.zeros((len(predictions), 8))\n",
        ")))[:, 3]\n",
        "\n",
        "# Display the predicted close prices\n",
        "print(f\"Predicted Close for the next 15 minutes: {predicted_close[-1]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CJ-qOeev1kA",
        "outputId": "78f3e9c5-d31e-4f4e-a8b7-264a26238f42"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
            "Predicted Close for the next 15 minutes: 2448.020122609156\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from ta.momentum import RSIIndicator\n",
        "from ta.trend import MACD\n",
        "from ta.volatility import BollingerBands\n",
        "\n",
        "# Step 1: Fetch Real-Time Data (latest 1-minute data for the last 15 minutes)\n",
        "data = yf.download(\"ZENTEC.NS\", interval=\"1m\", period=\"1d\")\n",
        "\n",
        "# Reset index to make sure we can access datetime easily\n",
        "data.reset_index(inplace=True)\n",
        "\n",
        "# Flatten the multi-level columns (Price and Ticker columns)\n",
        "data.columns = [col[0] if isinstance(col, tuple) else col for col in data.columns]\n",
        "\n",
        "# Drop the first row if necessary (it may contain extra metadata)\n",
        "data.drop(index=0, inplace=True)\n",
        "\n",
        "# Step 2: Preprocess the Data (Add Technical Indicators)\n",
        "data['Delta'] = data['Close'].diff()  # Delta (difference between consecutive Close prices)\n",
        "data['RSI'] = RSIIndicator(close=data['Close'], window=14).rsi()\n",
        "\n",
        "# Calculate MACD and Signal Line\n",
        "macd = MACD(close=data['Close'], window_slow=26, window_fast=12, window_sign=9)\n",
        "data['MACD'] = macd.macd()\n",
        "data['MACD_signal'] = macd.macd_signal()\n",
        "\n",
        "# Add Bollinger Bands\n",
        "bollinger = BollingerBands(close=data['Close'], window=20)\n",
        "data['BB_upper'] = bollinger.bollinger_hband()\n",
        "data['BB_lower'] = bollinger.bollinger_lband()\n",
        "\n",
        "# Add Lag Features\n",
        "for lag in [1, 3, 5, 10]:\n",
        "    data[f'Close_lag_{lag}'] = data['Close'].shift(lag)\n",
        "\n",
        "# Add Time-Based Features\n",
        "data['Hour'] = data['Datetime'].dt.hour\n",
        "data['Minute'] = data['Datetime'].dt.minute\n",
        "\n",
        "# Drop rows with NaN values\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "# Step 3: Scale the Data (to match the LSTM input)\n",
        "scaler = MinMaxScaler()\n",
        "scaled_data = scaler.fit_transform(data[['Open', 'High', 'Low', 'Close', 'Delta', 'RSI', 'MACD', 'MACD_signal',\n",
        "                                         'BB_upper', 'BB_lower', 'Hour', 'Minute']])\n",
        "\n",
        "# Prepare Sequences for LSTM (assuming the sequence length is 15)\n",
        "sequence_length = 15\n",
        "X_real_time = []\n",
        "for i in range(sequence_length, len(scaled_data)):\n",
        "    X_real_time.append(scaled_data[i-sequence_length:i])\n",
        "\n",
        "X_real_time = np.array(X_real_time)\n",
        "\n",
        "# Make Predictions (using the trained LSTM model)\n",
        "predictions = model.predict(X_real_time)\n",
        "\n",
        "# Inverse transform to get the original price scale\n",
        "predicted_close = scaler.inverse_transform(np.column_stack((\n",
        "    np.zeros((len(predictions), 3)), predictions, np.zeros((len(predictions), 8))\n",
        ")))[:, 3]\n",
        "\n",
        "# Get the last datetime from the dataset and create new datetimes for the next 15 minutes\n",
        "last_datetime = data['Datetime'].iloc[-1]\n",
        "time_intervals = [last_datetime + pd.Timedelta(minutes=i) for i in range(1, 16)]\n",
        "\n",
        "# Create a DataFrame to display the predicted close prices and the corresponding datetimes\n",
        "predicted_data = pd.DataFrame({\n",
        "    'Datetime': time_intervals,\n",
        "    'Predicted_Close': predicted_close[-15:]\n",
        "})\n",
        "\n",
        "# Display the results\n",
        "print(predicted_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FAFfYGnwQTY",
        "outputId": "b9da3455-a420-4fd6-dc99-50dc7e39c0d3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "                    Datetime  Predicted_Close\n",
            "0  2025-01-06 10:00:00+00:00      2454.866582\n",
            "1  2025-01-06 10:01:00+00:00      2453.497283\n",
            "2  2025-01-06 10:02:00+00:00      2452.204874\n",
            "3  2025-01-06 10:03:00+00:00      2451.270341\n",
            "4  2025-01-06 10:04:00+00:00      2450.414591\n",
            "5  2025-01-06 10:05:00+00:00      2449.590842\n",
            "6  2025-01-06 10:06:00+00:00      2449.115443\n",
            "7  2025-01-06 10:07:00+00:00      2449.015159\n",
            "8  2025-01-06 10:08:00+00:00      2449.082413\n",
            "9  2025-01-06 10:09:00+00:00      2449.321983\n",
            "10 2025-01-06 10:10:00+00:00      2449.310784\n",
            "11 2025-01-06 10:11:00+00:00      2449.279982\n",
            "12 2025-01-06 10:12:00+00:00      2449.062046\n",
            "13 2025-01-06 10:13:00+00:00      2448.655835\n",
            "14 2025-01-06 10:14:00+00:00      2448.020123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2cd01rvswXf7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}